---
title: 面试总结
toc: true
date: 2017-05-11 17:38:52
category: 
	- 文档
	- 面试总结
tags: 

---

# 面试总结
每一次面试都是对自己的技术知识的积累和提升，详细记录下那些面试中没有答出来或者没有答好的问题是必须的

<!--more-->
## 网络
1.Java Socket编程步骤
① 创建ServerSocket和Socket
② 打开连接到Socket的输入/输出流
③ 按照协议对Socket进行读/写操作
④ 关闭输入输出流、关闭Socket

服务端
① 创建ServerSocket对象，绑定监听端口
② 通过accept()方法监听客户端请求
③ 连接建立后，通过输入流读取客户端发送的请求信息
④ 通过输出流向客户端发送相应信息
⑤ 关闭相关资源

bind() - accept() - read() - write() - close()

客户端
① 创建Socket对象，指明需要连接的服务器的地址和端口号
② 连接建立后，通过输出流想服务器端发送请求信息
③ 通过输入流获取服务器响应的信息
④ 关闭响应资源 

connect() - write() - read() - close()

2.epoll模型
event poll，事件驱动，与select/poll最大的区别就是只监听活跃的Channal;

3.HTTP缓存

## GC
1.引用计数的循环引用问题如何解决？
根搜索回溯，判断循环引用的对象是否还存活

2.哪些类可以是根
final static 虚拟机栈存在引用 native栈存在引用

3.CMS收集器“浮动垃圾”参数过小如何解决
浮动垃圾：标记结束后，gc线程正在回收时又产生的新垃圾
解决：提前回收策略，或者配合使用其他收集器


## 数据库
1.MongoDB为什么说比MySQL性能好
因为MongoDB会先申请一大块内存，客户端的读写操作都是在内存中操作，MongoDB再负责落地，因此MongoDB是十分耗内存空间的。

2.MySQL事务
事务，一组不可被分割执行的SQL
**ACID**
A:原子性：要么全部执行，要么全部不执行
C:稳定性：执行前后状态稳定
I:隔离性：不与其他事务关联或互相影响
D:持久性：执行成功必须全部写入磁盘

隔离性实现原理：
锁机制，MyISAM使用表级别的锁，InnoDB采用行级别锁，提高数据表性能
InnoDB的锁通过锁定索引实现，查询条件中有主键则锁定主键，如果有索引先锁索引再锁主键，如果都没有则锁表
事务会导致脏读，不可重复读，幻读
InnoDB&Falcon引擎支持事务，MyISAM不支持事务

3.MySQL主从复制原理
主库开一个log dump 线程用来给从库 i/o线程传binlog
从库生成两个线程，一个I/O线程，一个SQL线程；
i/o线程去请求主库 的binlog，并将得到的binlog日志写到relay log（中继日志） 文件中；
SQL 线程，会读取relay log文件中的日志，并解析成具体操作，来实现主从的操作一致，而最终数据一致；

4.日志
undo:undo日志文件记录了数据在事务开始之前的值，当事务出现执行失败或者手动回滚时读取undo日志来恢复数据。
undo保证事务的ACI特性，但单纯使用undo会在事务提交前将数据写到磁盘，浪费I/O.

redo:记录数据修改后的值，可以避免事务提交前将数据写到磁盘，减少I/O。
undo保证事务的D特性

举个例子：
int a=3,b=5;
将a，b都修改成1，且保证a,b都修改成功

**only undo**

```
A.事务开始
B.write a=3 到 undo_buf
C.修改a=1
D.write b=5 到 undo_buf
E.修改b=1
F.将undo_buf写到undo磁盘（记录原始值，用于恢复）
G.将data_buf(新修改的数据)写到datafile磁盘
H.事务提交
```

如果事务在F之前崩溃则无影响，因为数据还未写入磁盘
如果事务在G之前崩溃或者回滚则可以根据undo恢复到初始状态

方案问题：F，G都需要写磁盘，浪费I/O


**undo+redo**

```
A.事务开始
B.write a=3 到 undo_buf
C.修改a=1 write到redo_buf
D.write b=5 到 undo_buf
E.修改b=1 write到redo_buf
F.将redo_buf写到redo磁盘（记录修改值）
G.事务提交
```

F之前崩溃由于所有数据都在内存，恢复后重新从磁盘载入就ok
FG之间的崩溃可以使用redo恢复
G之前的回滚可以使用undo来恢复

5.SQL优化
1）应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。
2）应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：
select id from t where num is null
可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：
select id from t where num=0
3）很多时候用 exists 代替 in 是一个好的选择
4）用Where子句替换HAVING 子句 因为HAVING 只会在检索出所有记录之后才对结果集进行过滤

6.索引
复合索引(A,B,C)

**以下查询语句都会走索引**
where A=x
where A=x and B=x 
where A=x and B=x and C=x
where B=x and A=x and C=x

**以下查询语句不会走索引**
where B=x 
where B=x and C=x


## Redis
1.单线程模型为什么还那么快
(1)基于内存操作
(2)不考虑并发、锁，也不会增加上下文切换等开销
(3)自封装的事件分离器，采用了epoll  + 自己实现的简单的事件框架


## Java基础
1.TreeMap是红黑树实现的
2.synchronized的是非公平锁（还好答对了，差点被面试官套路了）
3.线程池
ThreadPoolExecutor 的内部工作原理，整个思路总结起来就是 5 句话：
(1) 如果当前池大小 poolSize 小于 corePoolSize ，则创建新线程执行任务。
(2) 如果当前池大小 poolSize 大于 corePoolSize ，且等待队列未满，则进入等待队列
(3) 如果当前池大小 poolSize 大于 corePoolSize 且小于 maximumPoolSize ，且等待队列已满，则创建新线程执行任务。
(4) 如果当前池大小 poolSize 大于 corePoolSize 且大于 maximumPoolSize ，且等待队列已满，则调用拒绝策略来处理该任务。
(5) 线程池里的每个线程执行完任务后不会立刻退出，而是会去检查下等待队列里是否还有线程任务需要执行，如果在 keepAliveTime 里等不到新的任务了，那么线程就会退出。

排队有三种通用策略：

**直接提交**工作队列的默认选项是SynchronousQueue，它将任务直接提交给线程而不保持它们。在此，如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。直接提交通常要求无界 maximumPoolSizes 以避免拒绝新提交的任务。当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。

**无界队列**使用无界队列（例如，不具有预定义容量的LinkedBlockingQueue）将导致在所有 corePoolSize 线程都忙时新任务在队列中等待。这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize 的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web 页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。

**有界队列**当使用有限的 maximumPoolSizes 时，有界队列（如ArrayBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O 边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU 使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。

拒绝策略。常见有以下几种：

AbortPolicy ：不执行，会抛出 RejectedExecutionException 异常。
CallerRunsPolicy ：由调用者（调用线程池的主线程）执行。
DiscardOldestPolicy ：抛弃等待队列中最老的。
DiscardPolicy: 不做任何处理，即抛弃当前任务。

4.volatile如何保证从主内存取 而不是工作内存取
volatile会把工作内存中的值置为无效，利用MESI协议
volatile变量生成指令后会加上内存屏障

5.synchronized是对类的当前实例进行加锁，防止其他线程同时访问该类的该实例的所有synchronized块，而static synchronized恰好就是要控制类的所有实例的访问，static获取到的锁，属于类锁，而非static方法获取到的锁，是属于当前对象的锁，因此如果多线程访问不同实例的一个static方法和一个非static方法，static方法会阻塞。

6.Runnable接口和Thread类有什么区别
继承Thread类的，我们相当于拿出三件事即三个卖票10张的任务分别分给三个窗口，他们各做各的事各卖各的票各完成各的任务，因为MyThread继承Thread类，所以在new MyThread的时候在创建三个对象的同时创建了三个线程；
实现Runnable的， 相当于是拿出一个卖票10张得任务给三个人去共同完成，new MyThread相当于创建一个任务，然后实例化三个Thread，创建三个线程即安排三个窗口去执行。

Thread类：多个线程分别完成自己的任务
Runnable接口：多个线程共同完成一个任务

大多数情况下，如果只想重写 run() 方法，而不重写其他 Thread 方法，那么应使用 Runnable 接口。这很重要，因为除非程序员打算修改或增强类的基本行为，否则不应为该类（Thread）创建子类

7.解决高并发环境下数据插入重复问题
(1)synchronized锁整个方法  性能差
(2)synchronized块 锁可能重复的查询条件，如（索引id,联合索引id）
(3)负载均衡场景下以上都失效，必须在数据库层的唯一记录加select锁
(4)数据库添加行锁，不靠谱，因为行锁需要针对某条记录，但第一次insert时，数据还未持久化，因此无行锁。
(5)联合唯一索引，会导致过多索引空间占用大

8.serialVersionUID的作用
序列化时为了保持版本的兼容性，即在版本升级时反序列化仍保持对象的唯一性。
有两种生成方式：
（1）一个是默认的1L，比如：private static final long serialVersionUID = 1L;
（2）一个是根据类名、接口名、成员方法及属性等来生成一个64位的哈希字段，比如：
private static final long serialVersionUID = xxxxL;

如果你的类Serialized存到硬盘上面后，可是后来你却更改了类别的field(增加或减少或改名)，当你Deserialize时，就会出现Exception的，这样就会造成不兼容性的问题。 

9.Class文件结构
常量池放什么数据？
常量池主要存放两大类常量：字面量（Literal）和符号引用（Symbolic References），字面量主要就如文本字符串，声明为final的常量值等，符号引用一般指（1）类的接口和全限定名（2）字段的名称和描述符（3）方法的名称和描述符

10.Callable 和 Future接口
Callable是类似于Runnable的接口，实现Callable接口的类和实现Runnable的类都是可被其它线程执行的任务。

Callable和Runnable有几点不同：
1.Callable规定的方法是call()，而Runnable规定的方法是run().2.Callable的任务执行后可返回值，而Runnable的任务是不能返回值的。3.call()方法可抛出异常，而run()方法是不能抛出异常的。
4.运行Callable任务可拿到一个Future对象，

Future 表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。
通过Future对象可了解任务执行情况，可取消任务的执行，还可获取任务执行的结果。

11.hashCode()与equals()
equals相等，hashCode一定相等
equals不相等，hashCode不一定不相等
hashCode相等，equals不一定相等（想想HashMap原理）
hashCode不相等，equals一定不相等

因此hashCode一般用于集合的比较，是为了提高在散列结构存储中查找的效率，在线性表中没有作用
重写了equals方法，也有必要重写hashCode方法


## 其他
单进程单线程模型：Redis
多进程单线程模型：Nginx
单进程多线程模型：Memcached

## 编解码
Base64
一种编码技术，用于在HTTP环境下传递较长的标识信息。常见场景：迅雷下载的专用地址，qq旋风

编码说明：
	Base64编码要求把3个8位字节（3*8=24）转化为4个6位的字节（4*6=24），之后在6位的前面补两个0，形成8位一个字节的形式。 　　
举个例子
```
转换前 11111111, 11111111, 11111111 （二进制）
转换后 00111111, 00111111, 00111111, 00111111 （二进制）
```　
当然如果剩下的字符不足3个字节，则用0填充，输出字符使用'='，因此编码后输出的文本末尾可能会出现1或2个'='。另外，为了保证所输出的编码位可读字符，Base64制定了一个编码表，以便进行统一转换。编码表的大小为2^6=64，这也是Base64名称的由来，编码表可以去百度搜索一下，这里不再贴出。

## Zookeeper
1.脑裂
顾名思义，脑子裂开了，在Zookeeper这个服务中leader就是脑子，那么脑裂就是指出现多个master。开玩笑，怎么会有多个master,不是有leader选举吗？这里就要介绍一个概念了－假死。
假死：master并没有真的挂掉，但是集群中其他节点或者client认为master已经死掉，如何检测是否挂掉，通过心跳。那么出现假死的原因就是由于网络原因导致集群Follow与Master通信中断，Follow就认为Master已死。这种情况会出现两种状态
(1)集群子节点先发现master连接不上，这个时候剩下的follow会重新选举master,master选举完成后这时网络恢复，就会出现部分client连接在新master上，部分在旧master上，导致紊乱。
(2)client端先发现master连接不上。

如何避免？ 
在slaver切换的时候不再检查老的master出现问题后马上切换，而是在休眠一段足够的时间，确保老的master已经获知变更并且做了相关的shutdown清理工作了然后再注册成为master就能避免这类问题了，这个休眠时间一般定义为与Zookeeper定义的超时时间就够了，但是这段时间内系统不可用了。

2.client端与server端由于网络原因连接断开，那么server节点变更client还能同步到吗？
首先对于client来说，会在连接的时候注册watch监听事件到server上，server会维护watch列表，在服务端节点更新触发后，会主动通知client
（1）这种触发是一次性的，当数据改变的时候，那么一个Watch事件会产生并且被发送到客户端中。但是客户端只会收到一次这样的通知，如果以后这个数据再次发生改变的时候，之前设置Watch的客户端将不会再次收到改变的通知
（2）Watch的通知事件是从服务器发送给客户端的，而且是异步的，但是Zookeeper保证这种顺序性，也就是保证客户端一定先收到Watch事件的通知，再看到节点数据变更。
那么如果存在网络原因导致socket中断，在网络恢复后，如果需要的话，所有先前注册过的watch，都会被重新注册。通常这是完全透明的。只有在一个特殊情况下，watch可能会丢失：对于一个未创建的znode的exist watch，如果在客户端断开连接期间被创建了，并且随后在客户端连接上之前又删除了，这种情况下，这个watch事件可能会被丢失。

## 实战
1.线上环境出现大量缓存穿透现象（伪造key请求），最简单的解决办法是什么？
对key进行监控，同一个key连续n次没有从缓存以及库中查询到结果，说明存在恶意请求，则对该key做特殊处理。
